---
title: "CDFW Stream Restoration Siting Analysis"
author: "Lucy Andrews"
date: "12/6/2021"
output: html_document
---

# SET UP

## Load packages

```{r warning = FALSE, message = FALSE}
# load packages
# tidy syntax
library(tidyverse)
library(magrittr)

# data cleaning and presentation
library(janitor)
library(glue)
library(units)
library(knitr)
library(kableExtra)

# file import and management
library(here)
library(readxl)
library(googledrive)
library(fst)

# spatial data
library(sf)
library(raster)
library(rgdal)
library(tigris)
library(rmapshaper)
library(areal)

# statistics
library(spdep)
library(corrplot)
library(MatchIt)
library(survival)
library(randomForest)

# census data
library(tidycensus)

# visualization
library(ggnewscale)
library(ggpubr)
library(ggsn)
library(ggspatial)
library(scales)

# hydrologic data
library(nhdR)
library(nhdplusTools)
```

## Specify global options

```{r}
# specify global options
# no stringAsFactors
options(stringsAsFactors = FALSE)

# cache tigris sf objects
options(tigris_use_cache = TRUE)

# work in CRS EPSG 4269 (NAD83)
global_crs <- st_crs(4269)

# don't default to scientific notation in numeric display
options(scipen = 999)

# set a long timeout limit for file download
options(timeout = 30000)

# specify NHD ftypes to drop from analysis
drop_ftypes <- c("Coastline", "Pipeline", "Connector")

# set buffer distances
buffer_drop_control <- set_units(1, "km") # distance between restoration projects and control points
buffer_pollution <- set_units(15, "km") # distance for pollution attribute creation
buffer_ses <- set_units(1, "km") # distance for SES attribute creation

# specify visualization color options
restoration_color <- "chartreuse4"
control_color <- "darkorange1"
drop_color <- "gold1"
territory_color <- "lightblue"
fill_accent <- "grey50"
line_accent <- "lightblue4"
line_mute <- "grey75"
```

## Import custom functions

```{r}
# import custom functions contained in separate .R file
source(here("scripts", "final_code", "agu_poster_fxns.R"))
```

## Create directories

```{r}
# create directories
create_directory(here("raw_data"))
create_directory(here("cleaned_data"))
create_directory(here("output_data"))
```

## Import California boundary as sf object

```{r}
# import CA state boundary as sf object
ca_boundary <- get_ca_boundary(crs = global_crs)
```

## Create base map object

```{r}
# create base map object
ca_base_map <- ggplot() +
  geom_sf(data = ca_boundary, fill = "grey93") +
  annotation_scale(data = ca_boundary,
                   location = "tr",
                   bar_cols = c("grey80", "white"),
                   line_col = "darkgrey",
                   text_col = "darkgrey") + 
  annotation_north_arrow(data = ca_boundary,
                         location = "bl",
                         height = unit(0.7, "cm"),
                         width = unit(0.5, "cm"),
                         style = north_arrow_orienteering(fill = c("grey80", "grey80"),
                                                          line_col = "darkgrey",
                                                          text_col = "darkgrey",
                                                          text_size = 6)) +
  theme_minimal() +
  theme(legend.position = "bottom",
        panel.background = element_rect(fill = "white", color = "white"),
        plot.background = element_rect(fill = "white", color = "white"))

ca_base_map
```



# IMPORT AND CLEAN RESTORATION DATA

## Download restoration data

```{r}
# create directories
create_directory(here("raw_data", "restoration_terr")) # service territory area
create_directory(here("raw_data", "restoration_proj")) # restoration project locations

# specify dataset urls
restoration_terr_url <- "https://filelib.wildlife.ca.gov/Public/BDB/GIS/BIOS/Public_Datasets/700_799/ds734.zip"
restoration_proj_url <- "https://filelib.wildlife.ca.gov/Public/BDB/GIS/BIOS/Public_Datasets/100_199/ds168.zip"

# download datasets as zipped files
download_from_url(url = restoration_terr_url,
                  filename = "ds734.zip",
                  dir = here("raw_data", "restoration_terr"))

download_from_url(url = restoration_proj_url,
                  filename = "ds168.zip",
                  dir = here("raw_data", "restoration_proj"))

# unzip datasets into directory in which the zipped files are located
unzip_local(zipped_file = "ds734.zip",
            directory = here("raw_data", "restoration_terr"))

unzip_local(zipped_file = "ds168.zip",
            directory = here("raw_data", "restoration_proj"))

# clean up
rm(restoration_terr_url, restoration_proj_url)
invisible(gc())
```

## Read in and clean restoration data

### Read in and clean restoration territory data

```{r}
# read in and clean restoration territory sf objects
# geometry: MULTIPOLYGON
restoration_terr <- st_read(dsn = here("raw_data", "restoration_terr", "ds734.shp"),
                            quiet = TRUE) %>%
  st_transform(crs = global_crs) %>%
  rename(huc2 = HUC_2,
         huc4 = HUC_4,
         huc6 = HUC_6,
         huc8 = HUC_8,
         huc8_state = HU_8_STATE,
         fips_code = FIPS_C,
         huc10_name = HU_10_NAME) %>%
  rename_with(tolower) %>%
  ms_simplify(keep = 0.05) %>% # simplify geometry for faster mapping
  mutate(is_valid = st_is_valid(geometry)) %>%
  filter(is_valid) %>% # drop invalid geometries
  dplyr::select(-is_valid)

# union restoration territory objects to create a single sf object
restoration_terr <- restoration_terr %>%
  st_union() %>%
  st_as_sf() %>%
  mutate(fill_val = "restoration_terr")
```

### Confirm restoration territory on a map

```{r}
# create a map of restoration territory
ca_base_map +
  geom_sf(data = restoration_terr, fill = territory_color, lwd = 0) +
  theme_minimal()
```

### Read in restoration project data

```{r warning = FALSE}
# read in and clean restoration projects sf object
# geometry: none (dataframe, but contains longitude and latitude coordinates)
restoration_proj <- st_read(dsn = here("raw_data", "restoration_proj", "ds168.gdb"),
                            layer = "ds168_ex",
                            quiet = TRUE) %>%
  rename(obs_id = ProjectID) %>%
  rename_with(tolower) %>%
  st_as_sf(coords = c("center_longitude", "center_latitude"),
           crs = global_crs) %>%
  mutate(color_val = "restoration_proj")

# check number of initial project records
nrow(restoration_proj)
```

### Map initial restoration project data

```{r}
# map restoration projects (full dataset)
ca_base_map +
  geom_sf(data = restoration_terr, aes(fill = fill_val), lwd = 0) +
  scale_fill_manual(values = territory_color,
                    name = element_blank(),
                    labels = "CDFW grant territory") +
  geom_sf(data = restoration_proj, aes(color = color_val), size = 0.6) +
  scale_color_manual(values = restoration_color,
                     name = element_blank(),
                     labels = "CDFW restoration project") +
  guides(color = guide_legend(override.aes = list(size = 3)))

ggsave(filename = "restoration_sites_all.png", path = here("figs"))
```

### Clean restoration project data

```{r}
# identify project type values to drop
drop_project_type <- c("Water Measuring Devices",
                       "Monitoring Watershed Restoration",
                       "AmericCorps",
                       "Project Design",
                       "Public Involvement and Capacity Building",
                       "Private Sector Technical Training and Education",
                       "Public School Watershed and Fishery Conservation Education Project",
                       "Cooperative Rearing",
                       "Watershed and Regional Organization",
                       "Watershed Evaluation, Assessment, Planning",
                       "Monitoring Status and Trends")

# identify work status values to drop
drop_cal_work_status <- c("Terminated/Cancelled",
                          "TerminateCancel")

# identify grant status values to drop
drop_grant_status <- c("Cancelnofundsspent")

# add column to indicate drop
restoration_proj <- restoration_proj %>%
  mutate(drop = case_when(project_type %in% drop_project_type ~ TRUE,
                          cal_work_status %in% drop_cal_work_status ~ TRUE,
                          grant_status %in% drop_grant_status ~ TRUE,
                          TRUE ~ FALSE))

# check count of records to keep and to drop
restoration_proj %>%
  st_drop_geometry() %>%
  count(drop)
```

```{r}
# map project records to drop
ca_base_map +
  geom_sf(data = restoration_terr, aes(fill = fill_val), lwd = 0) +
  scale_fill_manual(values = territory_color,
                    name = element_blank(),
                    labels = "CDFW grant territory") +
  geom_sf(data = restoration_proj, aes(color = drop), size = 0.6) +
  facet_wrap(~drop) +
  scale_color_manual(values = c(restoration_color, drop_color),
                     name = element_blank(),
                     labels = c("project retained\n(physical environment change)",
                                "project dropped\n(education, planning, monitoring, hatchery)")) +
  theme(strip.text = element_blank()) +
  guides(color = guide_legend(override.aes = list(size = 3)))

ggsave(filename = "restoration_sites_keep_drop_proj_type.png", path = here("figs"))

# map project records to drop
ca_base_map +
  geom_sf(data = restoration_terr, aes(fill = fill_val), lwd = 0) +
  scale_fill_manual(values = territory_color,
                    name = element_blank(),
                    labels = "CDFW grant territory") +
  geom_sf(data = filter(restoration_proj, drop), aes(color = drop), size = 0.6) +
  scale_color_manual(values = restoration_color,
                     name = element_blank(),
                     labels = "project retained\n(physical environment change)") +
  theme(strip.text = element_blank()) +
  guides(color = guide_legend(override.aes = list(size = 3)))

ggsave(filename = "restoration_sites_keep_proj_type.png", path = here("figs"))

# drop undesired project records
restoration_proj <- restoration_proj %>%
  filter(!drop) %>%
  dplyr::select(-drop) %>%
  mutate(obs_type = "restoration") %>%
  dplyr::select(-geometry, everything(), geometry)

# clean up
rm(drop_project_type, drop_cal_work_status, drop_grant_status)
invisible(gc())
```



# IMPORT AND CLEAN NHD DATA

## Download NHD data

```{r warning = FALSE, message = FALSE}
# create directory
create_directory(here("raw_data", "nhd_flowlines"))

# set nhdR download directory path
Sys.setenv(nhdR_path = here("raw_data", "nhd_flowlines"))

# download flowlines, attribute data, and runoff modeling data
# VPUs 17 (PNW) and 18 (CA)
# NHDSnapshot: basic flowlines
nhd_plus_get(vpu = 17, component = "NHDSnapshot")
nhd_plus_get(vpu = 18, component = "NHDSnapshot")

# NHDPlusAttributes: basic attributes
nhd_plus_get(vpu = 17, component = "NHDPlusAttributes")
nhd_plus_get(vpu = 18, component = "NHDPlusAttributes")

# EROMExtension: climatic and hydrologic attributes
nhd_plus_get(vpu = 17, component = "EROMExtension")
nhd_plus_get(vpu = 18, component = "EROMExtension")
```

## Read in and clean flowlines

```{r}
# read in flowlines
flowlines_17 <- nhd_plus_load(vpu = 17,
                              component = "NHDSnapshot",
                              dsn = "NHDFlowline") %>%
  st_transform(crs = global_crs)

flowlines_18 <- nhd_plus_load(vpu = 18,
                              component = "NHDSnapshot",
                              dsn = "NHDFlowline") %>%
  st_transform(crs = global_crs)

# create and clean a single flowlines object
flowlines <- rbind(flowlines_17, flowlines_18) %>%
  rename(length_km = LENGTHKM) %>%
  rename_with(.fn = tolower) %>%
  dplyr::select(comid, gnis_id, gnis_name, length_km, ftype) %>%
  filter(ftype %notin% drop_ftypes) %>% # drop unwanted ftypes
  # drop flowlines outside of CA boundary
  st_join(dplyr::select(ca_boundary, geometry), left = FALSE)

# identify flowlines in the restoration study area
flowlines_study_area <- flowlines %>%
  st_join(restoration_terr, join = st_intersects, left = FALSE)

# add column to flowlines indicating whether flowline is in study area
flowlines <- flowlines %>%
  mutate(in_study_area = comid %in%flowlines_study_area$comid)

# clean up
rm(flowlines_17, flowlines_18, flowlines_study_area)
invisible(gc())
```

## Read in and clean flowlines value-added attributes

```{r}
# read in value-added attributes (VAA)
vaa_17 <- nhd_plus_load(vpu = 17,
                        component = "NHDPlusAttributes",
                        dsn = "PlusFlowlineVAA")

vaa_18 <- nhd_plus_load(vpu = 18,
                        component = "NHDPlusAttributes",
                        dsn = "PlusFlowlineVAA")

# create and clean a single VAA object
vaa <- rbind(vaa_17, vaa_18) %>%
  rename(comid = ComID,
         stream_order = StreamOrde,
         from_node = FromNode,
         to_node = ToNode,
         hydroseq = Hydroseq,
         level_path_i = LevelPathI,
         path_length = Pathlength,
         terminal_path = TerminalPa,
         up_level_path = UpLevelPat,
         up_hydroseq = UpHydroseq,
         down_level_path = DnLevelPat,
         down_hydroseq = DnHydroseq,
         tot_da_sqkm = TotDASqKM) %>%
  dplyr::select(comid, stream_order, tot_da_sqkm, from_node, to_node, hydroseq,
                level_path_i, path_length, terminal_path, up_level_path,
                down_level_path, down_hydroseq) %>%
  filter(comid %in% flowlines$comid)

# join VAA to flowlines
flowlines <- flowlines %>%
  left_join(vaa, by = "comid")

# clean up
rm(vaa_17, vaa_18, vaa)
invisible(gc())
```

## Read in slope attribute

```{r}
# read in slope attributes
elev_slope_17 <- nhd_plus_load(vpu = 17,
                               component = "NHDPlusAttributes",
                               dsn = "elevslope")

elev_slope_18 <- nhd_plus_load(vpu = 18,
                               component = "NHDPlusAttributes",
                               dsn = "elevslope")

# create a single slope object
elev_slope <- rbind(elev_slope_17, elev_slope_18) %>%
  rename_with(tolower) %>%
  mutate(slope = case_when(slope < 0 ~ NA_real_,
                           TRUE ~ slope)) %>%
  dplyr::select(comid, slope)

# join slope to flowlines
flowlines <- flowlines %>%
  left_join(elev_slope, by = "comid")

# clean up
rm(elev_slope_17, elev_slope_18, elev_slope)
```

## Read in and clean extended unit runoff method data

```{r}
# read in EROM tables
erom_17 <- nhd_plus_load(vpu = 17,
                         component = "EROMExtension",
                         dsn = "EROM_MA0001")

erom_18 <- nhd_plus_load(vpu = 18,
                         component = "EROMExtension",
                         dsn = "EROM_MA0001")

# create and clean a single EROM object
erom <- rbind(erom_17, erom_18) %>%
  rename(comid = ComID,
         mean_actual_discharge_cfs = Q0001E,
         mean_nat_discharge_cfs = Q0001C) %>%
  dplyr::select(comid, mean_actual_discharge_cfs, mean_nat_discharge_cfs) %>%
  mutate(nat_discharge_prop = mean_actual_discharge_cfs / mean_nat_discharge_cfs) %>%
  filter(comid %in% flowlines$comid)

# join EROM data to flowlines
flowlines <- flowlines %>%
  left_join(erom, by = "comid")

# clean up
rm(erom_17, erom_18, erom)
invisible(gc())
```

## Clean final VAA-enriched flowlines for necessary completeness

```{r}
# clean flowlines for complete data
# specify columns that must be complete
complete_cols <- c("stream_order", "slope")

# identify comid indices of complete flowlines
flowlines_complete <- flowlines[complete.cases(
  st_drop_geometry(dplyr::select(flowlines, all_of(complete_cols)))), ] %>%
  dplyr::select(comid)

# filter flowlines dataset to retain complete cases
flowlines <- flowlines %>%
  filter(comid %in% flowlines_complete$comid)

# clean up
rm(complete_cols, flowlines_complete)
invisible(gc())
```

## Check persisting NA values

```{r}
# count NAs in flowlines dataframe
count_df_na(st_drop_geometry(flowlines))
```

## Map retained flowlines and restoration projects

```{r}
# map flowlines, restoration territory study area, and restoration project sites
ca_base_map +
  geom_sf(data = restoration_terr, aes(fill = fill_val), lwd = 0) +
  scale_fill_manual(values = territory_color,
                    name = element_blank(),
                    labels = "CDFW grant territory") +
  geom_sf(data = filter(flowlines, stream_order > 2),
          aes(color = in_study_area), size = 0.35) +
  scale_color_manual(values = c(line_mute, line_accent),
                     guide = "none") +
  new_scale_color() +
  geom_sf(data = restoration_proj, aes(color = color_val), size = 0.6) +
  scale_color_manual(values = restoration_color,
                     name = element_blank(),
                     labels = "CDFW restoration project") +
  guides(color = guide_legend(override.aes = list(size = 3)))

ggsave(filename = "restoration_sites_keep_flowlines.png", path = here("figs"))
```

## Map EROM attributes

```{r}
# map flowlines, restoration territory study area, and restoration project sites
ca_base_map +
  geom_sf(data = filter(flowlines, stream_order > 3) %>% arrange(mean_actual_discharge_cfs),
          aes(color = mean_actual_discharge_cfs), size = 0.6) +
  scale_color_gradient2(low = "lightblue1", mid = "lightblue2", high = "dodgerblue3",
                        midpoint = 0.1)
```



# CREATE CONTROL POINTS

## Generate flowline midpoints as control points

```{r cache = TRUE}
# get flowline midpoints
control_points <- flowlines %>%
  filter(in_study_area) %>%
  st_line_midpoints() %>%
  cbind(filter(flowlines, in_study_area) %>%
          dplyr::select(comid) %>%
          st_drop_geometry()) %>%
  mutate(obs_type = "control")

# print count of control points
print("count of control points in full state:")
nrow(control_points)
```



# FILTER STUDY POINTS FOR "URBAN AREAS" AND OVERLAP

## Import Census Bureau incorporated or census-designated places

```{r}
# load and clean Census Bureau "places" sf polygon objects
incorp_cdp <- places(state = "CA", year = 2020) %>%
  rename(place_fip = PLACEFP,
         geo_id = GEOID,
         name = NAME,
         type_code = LSAD) %>%
  mutate(is_valid = st_is_valid(geometry),
         incorp_cdp = TRUE) %>%
  filter(is_valid) %>%
  dplyr::select(place_fip, geo_id, name, type_code, incorp_cdp)
```

## Map incorporated or census-designated places

```{r}
# map incorporated or census-designated places
ca_base_map +
  geom_sf(data = incorp_cdp, fill = fill_accent, lwd = 0) +
  geom_sf(data = filter(flowlines, stream_order > 3),
          color = "black",
          size = 0.35,
          alpha = 0.5)
```

## Filter restoration and control points for intersection with incorporated or census-designated places

### Filter urban restoration points

```{r}
# filter restoration projects for intersection with incorporated and
# census-designated places
restoration_proj <- restoration_proj %>%
  st_join(dplyr::select(incorp_cdp, geometry, incorp_cdp)) %>%
  mutate(incorp_cdp = case_when(incorp_cdp ~ TRUE,
                                TRUE ~ FALSE))

# make a map
ca_base_map +
  geom_sf(data = incorp_cdp, aes(fill = incorp_cdp), lwd = 0) +
  scale_fill_manual(values = fill_accent,
                    name = element_blank(),
                    labels = "incorporated or\ncensus-designated place") +
  geom_sf(data = filter(flowlines, stream_order > 3),
          color = line_mute,
          size = 0.35,
          alpha = 0.5) +
  new_scale_color() +
  geom_sf(data = restoration_proj %>% arrange(desc(incorp_cdp)),
          aes(color = incorp_cdp),
          size = 0.7) +
  scale_color_manual(values = c(drop_color, restoration_color),
                     name = element_blank(),
                     labels = c("non-urban project\ndropped from analysis",
                                "urban project\n kept in analysis")) +
  guides(color = guide_legend(override.aes = list(size = 3)))

ggsave(filename = "restoration_sites_keep_drop_incorp_cdp.png", path = here("figs"))

ca_base_map +
  geom_sf(data = incorp_cdp, aes(fill = incorp_cdp), lwd = 0) +
  scale_fill_manual(values = fill_accent,
                    name = element_blank(),
                    labels = "incorporated or\ncensus-designated place") +
  geom_sf(data = filter(flowlines, stream_order > 3),
          color = line_mute,
          size = 0.35,
          alpha = 0.5) +
  new_scale_color() +
  geom_sf(data = filter(restoration_proj, incorp_cdp),
          aes(color = incorp_cdp),
          size = 0.7) +
  scale_color_manual(values = restoration_color,
                     name = element_blank(),
                     labels = "project retained\n(in incorporated or\ncensus-designated place)") +
  guides(color = guide_legend(override.aes = list(size = 3)))

ggsave(filename = "restoration_sites_keep_incorp_cdp.png", path = here("figs"))

ca_base_map +
  geom_sf(data = restoration_terr, aes(fill = fill_val), lwd = 0) +
  scale_fill_manual(values = territory_color,
                    name = element_blank(),
                    labels = "CDFW grant territory") +
  geom_sf(data = filter(restoration_proj, incorp_cdp),
          aes(color = incorp_cdp),
          size = 0.7) +
  scale_color_manual(values = restoration_color,
                     name = element_blank(),
                     labels = "project retained\n(in incorporated or\ncensus-designated place)") +
  guides(color = guide_legend(override.aes = list(size = 3)))

ggsave(filename = "restoration_sites_keep_incorp_cdp_terr.png", path = here("figs"))
```

### Filter urban control points

```{r}
# filter control projects for intersection with incorporated
# census-designated places
control_points <- control_points %>%
  st_join(dplyr::select(incorp_cdp, geometry, incorp_cdp)) %>%
  mutate(incorp_cdp = case_when(incorp_cdp ~ TRUE,
                                TRUE ~ FALSE))

# make a map
ca_base_map +
  geom_sf(data = incorp_cdp, aes(fill = incorp_cdp), lwd = 0) +
  scale_fill_manual(values = fill_accent,
                    name = element_blank(),
                    labels = "incorporated or\ncensus-designated place") +
  geom_sf(data = filter(flowlines, stream_order > 3),
          color = line_mute,
          size = 0.35,
          alpha = 0.5) +
  new_scale_color() +
  geom_sf(data = control_points %>% arrange(desc(incorp_cdp)),
          aes(color = incorp_cdp),
          size = 0.3) +
  scale_color_manual(values = c(drop_color, control_color),
                     name = element_blank(),
                     labels = c("non-urban control point\ndropped from analysis",
                                "urban control point\n kept in analysis")) +
  guides(color = guide_legend(override.aes = list(size = 3)))

ggsave(filename = "control_sites_incorp_cdp.png", path = here("figs"))
```

### Drop non-urban points

```{r}
# drop non-urban restoration projects
restoration_proj <- restoration_proj %>%
  filter(incorp_cdp) %>%
  dplyr::select(-incorp_cdp)

# drop non-urban control points
control_points <- control_points %>%
  filter(incorp_cdp) %>%
  dplyr::select(-incorp_cdp)

# clean up
rm(incorp_cdp)
invisible(gc())

print("restoration projects:")
nrow(restoration_proj)
print("control points:")
nrow(control_points)
```

## Drop control values that intersect with a buffer around restoration projects

```{r}
# create a buffered restoration sites sf object
restoration_proj_buffered <- restoration_proj %>%
  dplyr::select(obs_id) %>%
  st_buffer(dist = buffer_drop_control) %>%
  ms_simplify(keep = 0.05)

# identify control points to drop because
# they intersect with a restoration project buffer
control_points_drop <- control_points %>%
  st_join(dplyr::select(restoration_proj_buffered, geometry), left = FALSE)

print("control points co-located with restoration sites:")
nrow(control_points_drop)
print("co-location buffer:")
print(buffer_drop_control)

# drop control points that are too close to restoration projects
control_points <- control_points %>%
  filter(comid %notin% control_points_drop$comid) %>%
  rename(obs_id = comid)

print("remaining control points:")
nrow(control_points)

# clean up
rm(control_points_drop, restoration_proj_buffered)
invisible(gc())
```

## Create and map a single dataset of control and restoration sites

```{r}
# create a single study points sf object
study_points <- rbind(dplyr::select(restoration_proj, obs_id, obs_type),
                      control_points) %>%
  left_join(st_drop_geometry(dplyr::select(restoration_proj, -obs_type)),
                             by = "obs_id") %>%
  mutate(obs_type_binary = case_when(obs_type == "restoration" ~ 1,
                                     obs_type == "control" ~ 0))

# map study points
ca_base_map +
  geom_sf(data = filter(flowlines, stream_order > 2),
          aes(color = in_study_area), size = 0.1) +
  scale_color_manual(values = c(line_mute, line_accent),
                     guide = "none") +
  new_scale_color() + 
  geom_sf(data = study_points, aes(color = obs_type), size = 0.6) +
  scale_color_manual(values = c(control_color, restoration_color),
                     name = element_blank(),
                     labels = c("control point",
                                "CDFW restoration project")) +
  guides(color = guide_legend(override.aes = list(size = 3)))

ggsave(filename = "restoration_and_control.png", path = here("figs"))
```



# ADD ATTRIBUTES TO STUDY POINTS

## Associate study points with flowlines and flowline attributes

```{r}
# join flowline attributes to study points by nearest feature
study_points <- study_points %>%
  st_join(dplyr::select(flowlines, comid, ftype, stream_order, tot_da_sqkm,
                        slope, mean_actual_discharge_cfs),
          join = st_nearest_feature)

# check out a map
ca_base_map +
  geom_sf(data = filter(flowlines, in_study_area, stream_order > 2),
          aes(color = abs(log(slope))),
          size = 0.1) +
  scale_color_gradient(low = "firebrick4", high = "lightsalmon") +
  new_scale_color() +
  geom_sf(data = filter(study_points,
                        !is.na(mean_actual_discharge_cfs),
                        mean_actual_discharge_cfs > 0),
          aes(color = abs(log(mean_actual_discharge_cfs))),
          size = 0.6) +
  scale_color_gradient(low = "lightblue1", high = "dodgerblue3")
```

## Compute and add upstream network attributes

```{r cache = TRUE}
# create specifically formatted flowlines attributes dataframe for upstream analysis
ut_network <- flowlines %>%
  st_drop_geometry() %>%
  rename(COMID = comid,
         Pathlength = path_length,
         LENGTHKM = length_km,
         Hydroseq = hydroseq,
         LevelPathI = level_path_i,
         DnHydroseq = down_hydroseq) %>%
  dplyr::select(COMID, Pathlength, LENGTHKM, Hydroseq, LevelPathI, DnHydroseq)
  
# compute upstream stream length (including tributaries) for each study point
study_points <- study_points %>%
  rowwise() %>%
  mutate(upstream_length_km = get_upstream_length(comid = comid,
                                                  ut_network_df = ut_network),
         drainage_density = upstream_length_km / tot_da_sqkm) %>%
  ungroup()

# get rid of control points with Inf drainage densities
study_points <- study_points %>%
  filter(!is.infinite(drainage_density))

# check it out on a map
ca_base_map +
  geom_sf(data = filter(flowlines, stream_order > 2),
          color = "darkgrey",
          size = 0.1) +
  geom_sf(data = filter(study_points, upstream_length_km < 1000),
          aes(color = upstream_length_km),
          size = 0.6) +
  scale_color_gradient2(low = "lightblue2", mid = "lightblue2", high = "dodgerblue3",
                        midpoint = 5)

# clean up
rm(ut_network)
invisible(gc())
```

## Add HUC12 and ACE data

```{r}
# create directory
create_directory(here("raw_data", "ace"))

# specify url
ace_url <- "https://filelib.wildlife.ca.gov/Public/BDB/ACE/ACE_Summary_Datasets.zip"

# download file
download_from_url(url = ace_url,
                  filename = "ace_summary_datasets.zip",
                  directory = here("raw_data", "ace"))

# unzip file
unzip_local(zipped_file = "ace_summary_datasets.zip",
            directory = here("raw_data", "ace"))

# read in and clean ACE dataset
huc12 <- readOGR(dsn = here("raw_data", "ace", "ACE_Summary_Datasets", "ds2743.gdb")) %>%
  st_as_sf() %>%
  st_transform(crs = global_crs) %>%
  ms_simplify(keep = 0.05) %>%
  st_intersection(y = ca_boundary) %>%
  rename(huc12 = HUC12,
         huc12_name = Name,
         native_aquatic_rank = NtvAqRankSW,
         native_aquatic_index = NtvAqSumSW,
         native_fish_count = NtvFish,
         native_aquatic_invert_count = NtvAqInvt,
         native_aquatic_amphib_count = NtvAqAmph,
         native_aquatic_reptile_count = NtvAqRept) %>%
  mutate(huc12_area_sqkm = drop_units(set_units(st_area(geometry), "km^2"))) %>%
  dplyr::select(huc12, huc12_name, huc12_area_sqkm,
                native_aquatic_rank, native_aquatic_index, native_fish_count,
                native_aquatic_invert_count, native_aquatic_amphib_count,
                native_aquatic_reptile_count)

# enrich restoration projects with HUC12 and ACE
study_points <- st_join(study_points, huc12, join = st_intersects)

# clean HUC12
huc12 <- huc12 %>%
  dplyr::select(huc12, huc12_name, huc12_area_sqkm)

# map ACE data
ca_base_map +
  geom_sf(data = filter(flowlines, stream_order > 2),
          color = "darkgrey",
          size = 0.1) +
  geom_sf(data = study_points, aes(color = native_aquatic_rank), size = 0.6) +
  scale_color_gradient(low = "red", high = "dodgerblue3")
    
# clean up
rm(ace_url)
invisible(gc())
```

## Add environmental flows

```{r}
# create directory
create_directory(here("raw_data", "eflows"))

# specify url
eflows_url <- "https://s3-us-west-1.amazonaws.com/funcflow/resources/eflow_geodatabase.zip"

# download eflows
download_from_url(url = eflows_url,
                  filename = "eflows.zip",
                  directory = here("raw_data", "eflows"))

# unzip eflows
unzip_local(zipped_file = "eflows.zip",
            directory = here("raw_data", "eflows"))

# read in eflows data
eflows <- st_read(here("raw_data", "eflows", "Final_Classification_9CLASS",
                       "Final_Classification_9CLASS.shp")) %>%
  st_transform(crs = global_crs) %>%
  rename(eflows_class = CLASS,
         comid = COMID) %>%
  mutate(eflows_class = as.character(eflows_class)) %>%
  dplyr::select(eflows_class, comid) %>%
  distinct(comid, .keep_all = TRUE)

# add eflows to restoration projects
study_points <- study_points %>%
  st_join(y = dplyr::select(eflows, eflows_class), join = st_nearest_feature)

# check out on a map
ca_base_map +
  geom_sf(data = filter(flowlines, stream_order > 2),
          color = "darkgrey",
          size = 0.1) +
  geom_sf(data = study_points, aes(color = eflows_class), size = 0.6)

# clean up
rm(eflows, eflows_url)
invisible(gc())
```

## Add precipitation data

```{r warning = FALSE}
# create directory
create_directory(here("raw_data", "precip"))

# specify url
precip_url <- "https://stacks.stanford.edu/file/druid:fs379qr8881/data.zip"

# download zipped file of precip data
download_from_url(url = precip_url,
                  filename = "precip.zip",
                  directory = here("raw_data", "precip"))

# unzip precip data
unzip_local(zipped_file = "precip.zip",
            directory = here("raw_data", "precip"))

# read in precip raster
precip <- raster(here("raw_data", "precip", "cappt7100_14", "hdr.adf"))

# grab precip value for each restoration site
precip_extract <- extract(precip, study_points) %>%
  as_tibble() %>%
  rename(precip = value)

# bind to study points
study_points <- cbind(study_points, precip_extract)

# check it out on a map
ca_base_map +
  geom_sf(data = filter(flowlines, stream_order > 2),
          color = "darkgrey",
          size = 0.1) +
  geom_sf(data = study_points, aes(color = precip), size = 0.6) +
  scale_color_gradient(low = "lightblue3", high = "dodgerblue3")

# clean up
rm(precip_url, precip, precip_extract)
invisible(gc())
```

## Add CSCI

```{r}
# create directory
create_directory(here("raw_data", "csci"))

# specify file url
csci_url <- "https://indicators.ucdavis.edu/cwip/sites/default/files/data/indicator_59452/data_59452_all.csv"

# download file
download_from_url(url = csci_url,
                  filename = "csci_all.csv",
                  directory = here("raw_data", "csci"))

# read in CSCI file
csci <- read_csv(here("raw_data", "csci", "csci_all.csv"),
                     col_names = TRUE) %>%
  rename(index = "...1") %>%
  group_by(station_code) %>%
  summarize(csci_score = min(csci_score, na.rm = TRUE),
            cwip_score = cwip_score[which.min(csci_score)],
            stream_name = stream_name[which.min(csci_score)],
            station_code = station_code[which.min(csci_score)],
            sample_date = sample_date[which.min(csci_score)],
            latitude = latitude[which.min(csci_score)],
            longitude = longitude[which.min(csci_score)]) %>%
  rowid_to_column(var = "csci_index") %>%
  st_as_sf(coords = c("longitude", "latitude"), crs = global_crs)

# calculate the average CSCI score for all restoration sites
# using all CSCI observations within 10km of a restoration site
# aka intersecting a 10km buffer
csci_agg <- aggregate(dplyr::select(csci, csci_score, cwip_score),
                      dplyr::select(study_points, obs_id),
                      FUN = mean, 
                      join = function(x, y) st_is_within_distance(x, y, dist = buffer_pollution)) %>%
  st_drop_geometry()

# bind CSCI aggregated values to restoration projects
study_points <- cbind(study_points, csci_agg)

# clean up
rm(csci_url, csci_agg, csci)
invisible(gc())
```

## Add nitrates

```{r}
# create directory
create_directory(here("raw_data", "nitrates"))

# specify url
nitrates_url <- "https://indicators.ucdavis.edu/cwip/sites/default/files/data/indicator_32232/data_32232_all.csv"

# download file
download_from_url(url = nitrates_url,
                  filename = "nitrates_all.csv",
                  directory = here("raw_data", "nitrates"))

# read in nitrates file
nitrates <- read_csv(here("raw_data", "nitrates", "nitrates_all.csv"),
                     col_names = TRUE) %>%
  rename(index = "...1") %>%
  group_by(code) %>%
  summarize(nitrate_score = min(score, na.rm = TRUE),
            name = name[which.min(score)],
            code = code[which.min(score)],
            date = date[which.min(score)],
            lat = lat[which.min(score)],
            lon = lon[which.min(score)]) %>%
  st_as_sf(coords = c("lon", "lat"), crs = global_crs)

# calculate the average nitrates score for all restoration sites
# using all nitrates observations within 10km of a restoration site
# aka intersecting a 10km buffer
nitrates_agg <- aggregate(dplyr::select(nitrates, nitrate_score),
                          dplyr::select(study_points, obs_id),
                          FUN = mean, 
                          join = function(x, y) st_is_within_distance(x, y, dist = buffer_pollution)) %>%
  st_drop_geometry()

# bind CSCI aggregated values to restoration projects
study_points <- cbind(study_points, nitrates_agg)

# clean up
rm(nitrates_url, nitrates_agg, nitrates)
invisible(gc())
```

## Add 303d listed waterbodies

```{r warning = FALSE}
# create directory
create_directory(here("raw_data", "303d"))

# specify url
waterbodies_303d_lines_url <- "https://gispublic.waterboards.ca.gov/webmap/303d_2014_2016/files/IR_1416_Impaired_Lines.zip"

# download file
download_from_url(url = nitrates_url,
                  filename = "IR_1416_Impaired_Lines.zip",
                  directory = here("raw_data", "303d"))

# unzip file
unzip_local(zipped_file = "IR_1416_Impaired_Lines.zip",
            directory = here("raw_data", "303d"))

# specify url
waterbodies_303d_polygons_url <- "https://gispublic.waterboards.ca.gov/webmap/303d_2014_2016/files/IR_1416_Impaired_Polys.zip"

# download file
download_from_url(url = nitrates_url,
                  filename = "IR_1416_Impaired_Polys.zip",
                  directory = here("raw_data", "303d"))

# unzip file
unzip_local(zipped_file = "IR_1416_Impaired_Polys.zip",
            directory = here("raw_data", "303d"))

# read in
waterbodies_303d_lines <- st_read(here("raw_data", "303d", "IR_1416_Impaired_Lines")) %>%
  st_transform(crs = global_crs) %>%
  ms_simplify(keep = 0.05) %>%
  mutate(waterbody_303d = TRUE) %>%
  dplyr::select(waterbody_303d)

waterbodies_303d_polygons <- st_read(here("raw_data", "303d", "IR_1416_Impaired_Polys")) %>%
  st_transform(crs = global_crs) %>%
  ms_simplify(keep = 0.05) %>%
  mutate(waterbody_303d = TRUE,
         is_valid = st_is_valid(geometry)) %>%
  filter(is_valid) %>%
  dplyr::select(waterbody_303d)

# buffer restoration sites for intersection with 303d listed waterbodies
study_points_buffered <- st_buffer(study_points, dist = buffer_pollution) %>%
  dplyr::select(obs_id)

# intersect buffered restoration sites with 303d listed waterbodies
study_points_buffered_303d <- study_points_buffered %>%
  st_join(y = waterbodies_303d_lines) %>%
  st_join(y = waterbodies_303d_polygons) %>%
  st_drop_geometry() %>%
  group_by(obs_id) %>%
  summarize(streams_303d = max(waterbody_303d.x, na.rm = TRUE),
            lakes_ponds_303d = max(waterbody_303d.x, na.rm = TRUE))

# clean results
study_points_buffered_303d <- do.call(data.frame,
                                      lapply(study_points_buffered_303d,
                                             function(x) replace(x, is.infinite(x), NA)))

# join to restoration projects dataframe
study_points <- left_join(study_points, study_points_buffered_303d,
                          by = "obs_id")

# replace 303d NA values with 0
study_points$streams_303d[is.na(study_points$streams_303d)] <- 0
study_points$lakes_ponds_303d[is.na(study_points$lakes_ponds_303d)] <- 0

# create a single 303d column that combine stream, lakes, and ponds statuses
study_points <- study_points %>%
  rowwise() %>%
  mutate(any_303d = max(streams_303d, lakes_ponds_303d)) %>%
  ungroup()

# clean up
rm(waterbodies_303d_lines_url, waterbodies_303d_polygons_url,
   waterbodies_303d_lines, waterbodies_303d_polygons, study_points_buffered_303d,
   study_points_buffered)
invisible(gc())
```



# GENERATE SOCIOECONOMIC DATA

## Download block group geometry and socioeconomic data for Census

```{r cache = TRUE}
# pull block groups geometry and total population figures
block_groups <- get_decennial(state = "CA",
                              geography = "block group",
                              variables = c(tot_pop_count = "P001001"),
                              year = 2000,
                              geometry = TRUE) %>%
  st_transform(crs = global_crs) %>%
  rename(block_group_id = GEOID,
         tot_pop_count = value) %>%
  dplyr::select(block_group_id, tot_pop_count)

# pull total population of non-Hispanic white alone and median household income
nonhisp_white <- get_decennial(state = "CA",
                               geography = "block group",
                               variables = c(nonhisp_white_pop_count = "P007003",
                                             med_hh_income = "P053001"),
                               year = 2000,
                               geometry = FALSE) %>%
  pivot_wider(names_from = "variable", values_from = "value") %>%
  rename(block_group_id = GEOID) %>%
  dplyr::select(block_group_id, nonhisp_white_pop_count, med_hh_income)

# join all socioeconomic data together
block_groups <- block_groups %>%
  left_join(nonhisp_white, by = "block_group_id") %>%
  dplyr::select(-geometry, everything(), geometry)

# check it out on a map
ggplot() +
  geom_sf(data = ms_simplify(block_groups, keep = 0.01),
          aes(fill = med_hh_income), lwd = 0) +
  theme_minimal()

# clean up
rm(nonhisp_white)
invisible(gc())
```

## Create buffered study points

```{r}
# create polygons object of buffers around study points
study_points_buffered <- st_buffer(study_points, dist = buffer_ses) %>%
  dplyr::select(obs_id)
```

## Do areal interpolations

```{r}
# interpolate population values - extensive
aw_pop <- aw_interpolate(.data = st_transform(study_points_buffered, crs = st_crs(3488)),
                         tid = obs_id,
                         source = st_transform(block_groups, crs = st_crs(3488)),
                         sid = block_group_id,
                         output = "tibble",
                         weight = "sum",
                         extensive = c("tot_pop_count", "nonhisp_white_pop_count")) %>%
  mutate(nonhisp_white_prop = nonhisp_white_pop_count / tot_pop_count) %>%
  mutate(nonhisp_white_prop = case_when(nonhisp_white_prop > 1 ~ 1,
                                        TRUE ~ nonhisp_white_prop),
         bipoc_prop = 1 - nonhisp_white_prop) %>%
  rename(pop_density = tot_pop_count) %>%
  dplyr::select(-nonhisp_white_pop_count)

# interpolate income value - intensive
aw_income <- aw_interpolate(.data = st_transform(study_points_buffered, crs = st_crs(3488)),
                            tid = obs_id,
                            source = st_transform(block_groups, crs = st_crs(3488)),
                            sid = block_group_id,
                            output = "tibble",
                            weight = "sum",
                            intensive = "med_hh_income")
```

## Add areal interpolations to study points

```{r}
# join areally interpolated socioeconomic data to study points
study_points <- study_points %>%
  left_join(aw_pop, by = "obs_id") %>%
  left_join(aw_income, by = "obs_id")

# check it out on a map
ca_base_map +
  geom_sf(data = filter(flowlines, stream_order > 2),
          color = "darkgrey",
          size = 0.1) +
  geom_sf(data = study_points, aes(color = med_hh_income), size = 0.6) +
  scale_color_gradient(low = "darkseagreen1", high = "darkgreen")

# clean up
rm(aw_income, aw_pop, block_groups, study_points_buffered)
invisible(gc())
```



# CHECK DATA COMPLETENESS AND CORRELATION

## Count missing data

```{r}
# count NAs in each column of the study points object
count_df_na(st_drop_geometry(study_points))
```

## Check correlations

Note: explore correlations more thoroughly and decide whether/which variables to drop.

```{r}
# list variables to assess for correlation/covariation
corr_check_vars <- c("tot_da_sqkm", "slope", "mean_actual_discharge_cfs",
                     "drainage_density", "native_aquatic_index", "precip",
                     "csci_score", "nitrate_score", "any_303d",
                     "pop_density", "bipoc_prop", "med_hh_income")

# create a dataframe subsetted for columns of interest in correlation
corr_check_df <- study_points %>%
  dplyr::select(all_of(corr_check_vars)) %>%
  st_drop_geometry()

# keep only complete cases
corr_check_df <- corr_check_df[complete.cases(corr_check_df), ]

# make a Pearson's correlation matrix
cor(corr_check_df) %>%
  corrplot(., method = "number", type = "upper")

# clean up
rm(corr_check_vars, corr_check_df)
```

Mean annual discharge and total drainage area should obviously be correlated, so that's good to see.
We will need to pick one of the two variables. I could go either way - total drainage area is a more reliable
value (in terms of data source), but discharge is the variable of direct theoretical interest.

## Drop incomplete cases

```{r}
# identify columns to use in assessing completeness
# currently dropped: tot_da_sqkm, nitrate_score
complete_vars <- c("slope", "mean_actual_discharge_cfs", "drainage_density",
                   "native_aquatic_index", "eflows_class", "precip",
                   "csci_score", "any_303d", "pop_density",
                   "bipoc_prop", "med_hh_income")

# keep only complete cases across columns of interest
study_points_complete <- study_points[
  complete.cases(st_drop_geometry(dplyr::select(study_points, all_of(complete_vars)))), ]

# summarize remaining study points - original and remaining
study_points %>%
  st_drop_geometry() %>%
  count(obs_type)

study_points_complete %>%
  st_drop_geometry() %>%
  count(obs_type)
```



# CREATE MATCHES

## Run first match analysis without a caliper - genetic matching method

### Set up match analysis

```{r}
# specify variables to use in the matching formula
match_vars <- c("slope", "mean_actual_discharge_cfs", "drainage_density",
                "native_aquatic_index", "precip",
                "csci_score", "any_303d", "pop_density")

# create a match formula
match_formula <- as.formula(glue('obs_type_binary ~ {glue_collapse(match_vars, "+")}'))
```

### Run a version without a caliper

```{r}
# do the matching without a caliper first
matchit_no_caliper <- matchit(formula = match_formula,
                              data = study_points_complete,
                              method = "genetic",
                              distance = "glm",
                              caliper = NULL)

# extract and clean the match data
pairs_no_caliper <- match.data(matchit_no_caliper) %>%
  mutate(subclass = as.numeric(levels(subclass))[subclass])

# create lines connecting pairs
lines_no_caliper <- pairs_no_caliper %>%
  group_by(subclass) %>%
  summarize(match_id = mean(subclass)) %>%
  st_cast("LINESTRING") %>%
  mutate(euc_distance_km = drop_units(set_units(st_length(geometry), "km")))

# create caption text
cap_text <- paste("count of pairs:", nrow(lines_no_caliper), collapse = " ")

# check it out on a map
ca_base_map +
  geom_sf(data = restoration_terr, fill = territory_color, lwd = 0) +
  geom_sf(data = lines_no_caliper, aes(color = euc_distance_km)) +
  scale_color_gradient2(low = "dodgerblue", mid = "dodgerblue3", high = "red",
                        midpoint = 400,
                        name = "Euclidean\ndistance (km)") +
  new_scale_color() +
  geom_sf(data = pairs_no_caliper, aes(color = obs_type), size = 1) +
  scale_color_manual(values = c(control_color, restoration_color),
                     name = element_blank(),
                     labels = c("control point", "CDFW restoration project")) +
  guides(color = guide_legend(override.aes = list(size = 3))) +
  labs(caption = cap_text) +
  theme(legend.position = "right")

ggsave(filename = "paired_points_and_lines_no_caliper.png", path = here("figs"))
```

### Check out Euclidean distance distribution

```{r}
# check out density plot of distances between paired points
ggplot() +
  geom_histogram(data = lines_no_caliper,
                 aes(x = euc_distance_km),
                 fill = "lightgrey",
                 color = "darkgrey",
                 binwidth = 25,
                 boundary = 0) +
  ylim(0, 150) +
  xlab("Euclidean distance between paired points (km)") +
  ylab("Count of pairs") +
  labs(caption = cap_text) +
  theme_minimal() +
  theme(legend.position = "bottom",
        panel.background = element_rect(fill = "white", color = "white"),
        plot.background = element_rect(fill = "white", color = "white"))

ggsave(filename = "euc_distance_hist_no_caliper.png", path = here("figs"))
```

## Determine caliper size

```{r}
# determine standard deviation of matched pair distances
distance_sd <- sd(pairs_no_caliper$distance)

# calculate the caliper size
caliper_val <- 0.2 * log(distance_sd / (1 - distance_sd))
```

## Re-run the matching with a caliper

```{r}
# do the matching with a caliper this time
matchit_w_caliper <- matchit(formula = match_formula,
                             data = study_points_complete,
                             method = "genetic",
                             distance = "glm",
                             caliper = caliper_val)

# extract and clean the match data
pairs_w_caliper <- match.data(matchit_w_caliper) %>%
  mutate(subclass = as.numeric(levels(subclass))[subclass])

# create lines connecting pairs
lines_w_caliper <- pairs_w_caliper %>%
  group_by(subclass) %>%
  summarize(match_id = mean(subclass)) %>%
  st_cast("LINESTRING") %>%
  mutate(euc_distance_km = drop_units(set_units(st_length(geometry), "km")))

# create caption text
cap_text <- paste("count of pairs:", nrow(lines_w_caliper), collapse = " ")

# check it out on a map
ca_base_map +
  geom_sf(data = restoration_terr, fill = territory_color, lwd = 0) +
  geom_sf(data = lines_w_caliper, aes(color = euc_distance_km)) +
  scale_color_gradient2(low = "dodgerblue", mid = "dodgerblue3", high = "red",
                        midpoint = 400,
                        name = "Euclidean\ndistance (km)") +
  new_scale_color() +
  geom_sf(data = pairs_w_caliper, aes(color = obs_type), size = 1) +
  scale_color_manual(values = c(control_color, restoration_color),
                     name = element_blank(),
                     labels = c("control point", "CDFW restoration project")) +
  guides(color = guide_legend(override.aes = list(size = 3))) +
  labs(caption = cap_text) +
  theme(legend.position = "right")

ggsave(filename = "paired_points_and_lines_w_caliper.png", path = here("figs"))
```

### Check out Euclidean distance distribution for calipered run

```{r}
# check out density plot of distances between paired points
ggplot() +
  geom_histogram(data = lines_w_caliper,
                 aes(x = euc_distance_km),
                 fill = "lightgrey",
                 color = "darkgrey",
                 binwidth = 25,
                 boundary = 0) +
  ylim(0, 150) +
  xlab("Euclidean distance between paired points (km)") +
  ylab("Count of pairs") +
  labs(caption = cap_text) +
  theme_minimal() +
  theme(legend.position = "bottom",
        panel.background = element_rect(fill = "white", color = "white"),
        plot.background = element_rect(fill = "white", color = "white"))

ggsave(filename = "euc_distance_hist_w_caliper.png", path = here("figs"))
```

## Do it all over again for nearest neighbor match method

### Run a version without a caliper

```{r}
# do the matching without a caliper first
matchit_no_caliper_nearest <- matchit(formula = match_formula,
                              data = study_points_complete,
                              method = "nearest",
                              distance = "glm",
                              caliper = NULL)

# extract and clean the match data
pairs_no_caliper_nearest <- match.data(matchit_no_caliper_nearest) %>%
  mutate(subclass = as.numeric(levels(subclass))[subclass])

# create lines connecting pairs
lines_no_caliper_nearest <- pairs_no_caliper_nearest %>%
  group_by(subclass) %>%
  summarize(match_id = mean(subclass)) %>%
  st_cast("LINESTRING") %>%
  mutate(euc_distance_km = drop_units(set_units(st_length(geometry), "km")))

# create caption text
cap_text <- paste("count of pairs:", nrow(lines_no_caliper_nearest), collapse = " ")

# check it out on a map
ca_base_map +
  geom_sf(data = restoration_terr, fill = territory_color, lwd = 0) +
  geom_sf(data = lines_no_caliper_nearest, aes(color = euc_distance_km)) +
  scale_color_gradient2(low = "dodgerblue", mid = "dodgerblue3", high = "red",
                        midpoint = 400,
                        name = "Euclidean\ndistance (km)") +
  new_scale_color() +
  geom_sf(data = pairs_no_caliper_nearest, aes(color = obs_type), size = 1) +
  scale_color_manual(values = c(control_color, restoration_color),
                     name = element_blank(),
                     labels = c("control point", "CDFW restoration project")) +
  guides(color = guide_legend(override.aes = list(size = 3))) +
  labs(caption = cap_text) +
  theme(legend.position = "right")

ggsave(filename = "paired_points_and_lines_no_caliper_nearest.png", path = here("figs"))
```

### Check out Euclidean distance distribution

```{r}
# check out density plot of distances between paired points
ggplot() +
  geom_histogram(data = lines_no_caliper_nearest,
                 aes(x = euc_distance_km),
                 fill = "lightgrey",
                 color = "darkgrey",
                 binwidth = 25,
                 boundary = 0) +
  ylim(0, 150) +
  xlab("Euclidean distance between paired points (km)") +
  ylab("Count of pairs") +
  labs(caption = cap_text) +
  theme_minimal() +
  theme(legend.position = "bottom",
        panel.background = element_rect(fill = "white", color = "white"),
        plot.background = element_rect(fill = "white", color = "white"))

ggsave(filename = "euc_distance_hist_no_caliper_nearest.png", path = here("figs"))
```

## Determine caliper size

```{r}
# determine standard deviation of matched pair distances
distance_sd_nearest <- sd(pairs_no_caliper_nearest$distance)

# calculate the caliper size
caliper_val_nearest <- 0.2 * log(distance_sd_nearest / (1 - distance_sd_nearest))
```

## Re-run the matching with a caliper

```{r}
# do the matching with a caliper this time
matchit_w_caliper_nearest <- matchit(formula = match_formula,
                                     data = study_points_complete,
                                     method = "nearest",
                                     distance = "glm",
                                     caliper = caliper_val)

# extract and clean the match data
pairs_w_caliper_nearest <- match.data(matchit_w_caliper_nearest) %>%
  mutate(subclass = as.numeric(levels(subclass))[subclass])

# create lines connecting pairs
lines_w_caliper_nearest <- pairs_w_caliper_nearest %>%
  group_by(subclass) %>%
  summarize(match_id = mean(subclass)) %>%
  st_cast("LINESTRING") %>%
  mutate(euc_distance_km = drop_units(set_units(st_length(geometry), "km")))

# create caption text
cap_text <- paste("count of pairs:", nrow(lines_w_caliper_nearest), collapse = " ")

# check it out on a map
ca_base_map +
  geom_sf(data = restoration_terr, fill = territory_color, lwd = 0) +
  geom_sf(data = lines_w_caliper_nearest, aes(color = euc_distance_km)) +
  scale_color_gradient2(low = "dodgerblue", mid = "dodgerblue3", high = "red",
                        midpoint = 400,
                        name = "Euclidean\ndistance (km)") +
  new_scale_color() +
  geom_sf(data = pairs_w_caliper_nearest, aes(color = obs_type), size = 1) +
  scale_color_manual(values = c(control_color, restoration_color),
                     name = element_blank(),
                     labels = c("control point", "CDFW restoration project")) +
  guides(color = guide_legend(override.aes = list(size = 3))) +
  labs(caption = cap_text) +
  theme(legend.position = "right")

ggsave(filename = "paired_points_and_lines_w_caliper_nearest.png", path = here("figs"))
```

## Evaluate calipered match results - genetic matching method

### See summary

```{r}
# summarize match output
summary(matchit_w_caliper)
```

### View distribution in jitter plot

```{r}
# view the distribution of propensity scores
plot(matchit_w_caliper, type = "jitter", interactive = FALSE)
```

### Check covariate balance

```{r}
# view the covariate balance
plot(matchit_w_caliper, type = "qq", interactive = FALSE)
```

### See matched results in Love plot

```{r}
# create a Love plot
plot(summary(matchit_w_caliper))
```

## Compute summary statistics for matched populations

```{r}
# create box plot - BIPOC prop
ggplot() +
  geom_boxplot(data = pairs_w_caliper,
               aes(x = obs_type,
                   y = bipoc_prop,
                   color = obs_type,
                   fill = obs_type)) +
  scale_color_manual(values = c(control_color, restoration_color)) +
  scale_fill_manual(values = c("#ffcc9b", "#cef0ad")) +
  scale_y_continuous(labels = percent_format(),
                     breaks = seq(from = 0, to = 1, by = 0.2)) +
  xlab(element_blank()) +
  ylab("Proportion of residents who are BIPOC") +
  theme_minimal() +
  theme(legend.position = "none",
        panel.background = element_rect(fill = "white", color = "white"),
        plot.background = element_rect(fill = "white", color = "white"))

ggsave(filename = "bipoc_boxplot.png", path = here("figs"),
       width = 3, height = 7, units = "in")

# create box plot - income
ggplot() +
  geom_boxplot(data = pairs_w_caliper,
               aes(x = obs_type,
                   y = med_hh_income,
                   color = obs_type,
                   fill = obs_type)) +
  scale_color_manual(values = c(control_color, restoration_color)) +
  scale_fill_manual(values = c("#ffcc9b", "#cef0ad")) +
  scale_y_continuous(labels = dollar_format(),
                     limits = c(0, 200000)) +
  xlab(element_blank()) +
  ylab("Median annual househould income") +
  theme_minimal() +
  theme(legend.position = "none",
        panel.background = element_rect(fill = "white", color = "white"),
        plot.background = element_rect(fill = "white", color = "white"))

ggsave(filename = "mhi_boxplot.png", path = here("figs"),
       width = 3, height = 7, units = "in")
```

```{r}
# take a quick look at parametric summary statistics
pairs_w_caliper %>%
  st_drop_geometry() %>%
  group_by(obs_type) %>%
  summarize(mean_hh_income = mean(med_hh_income),
            iqr_hh_income = IQR(med_hh_income),
            min_hh_income = min(med_hh_income),
            max_hh_income = max(med_hh_income),
            mean_bipoc_prop = mean(bipoc_prop),
            iqr_bipoc_prop = IQR(bipoc_prop),
            min_bipoc_prop = min(bipoc_prop),
            max_bipoc_prop = max(bipoc_prop))
```



# RUN REGRESSION ANALYSES

## Check interaction option

Best regression uses interaction, based on AIC.

```{r}
# run a conditional logistic regression
cond_log_regression <- clogit(obs_type_binary ~
                                  med_hh_income * bipoc_prop + strata(subclass),
                                data = match.data(matchit_w_caliper))

# check results
summary(cond_log_regression)

AIC(cond_log_regression)
```

## Check Moran's I

```{r}
# grab coordinates
pairs_w_caliper <- pairs_w_caliper %>%
  mutate(lat = sf::st_coordinates(.)[ , 2],
         lon = sf::st_coordinates(.)[ , 1])

# set global option for regions with no neighbors
set.ZeroPolicyOption(TRUE)

# set up Moran's I test
weights = nb2listw(dnearneigh(pairs_w_caliper, 
                              d1 = 0.1 * 1000, d2 = 5 * 1000),
                   style = "C",
                   zero.policy = TRUE)

# confirm match correct results
pairs_w_caliper$residuals <- residuals(cond_log_regression)

AIC(cond_log_regression)

# test Moran's I
moran.test(pairs_w_caliper$residuals, weights, alternative = "two.sided")
```

### Run conditional logistic regression with lat/long

```{r}
# add lat and lon values to pairs object
pairs_w_caliper_no_sf <- pairs_w_caliper %>%
  st_drop_geometry()
  
# check regression with lat and lon terms
cond_log_regression_latlon <- clogit(obs_type_binary ~
                                  med_hh_income * bipoc_prop + lat + lon + strata(subclass),
                                data = pairs_w_caliper_no_sf)

# view results
summary(cond_log_regression_latlon)

cond_log_regression_latlon$residuals <- residuals(cond_log_regression_latlon)

AIC(cond_log_regression_latlon)

# test Moran's I again
moran.test(cond_log_regression_latlon$residuals, weights, alternative = "two.sided")
```





