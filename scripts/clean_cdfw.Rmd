---
title: "clean_cdfw"
author: "Lucy Andrews"
date: "9/27/2021"
output: html_document
---

# Set up

## Packages, options, and functions

```{r setup}
# set up packages, options, and functions

# load packages
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(magrittr))
suppressPackageStartupMessages(library(janitor))
suppressPackageStartupMessages(library(foreach))
suppressPackageStartupMessages(library(doParallel))
suppressPackageStartupMessages(library(here))
suppressPackageStartupMessages(library(readxl))
suppressPackageStartupMessages(library(googledrive))
suppressPackageStartupMessages(library(readr))
suppressPackageStartupMessages(library(stringr))
suppressPackageStartupMessages(library(sf))
suppressPackageStartupMessages(library(raster))
suppressPackageStartupMessages(library(elevatr))
suppressPackageStartupMessages(library(exactextractr))
suppressPackageStartupMessages(library(fst))
suppressPackageStartupMessages(library(rgdal))
suppressPackageStartupMessages(library(units))
suppressPackageStartupMessages(library(tigris))
suppressPackageStartupMessages(library(tidycensus))
suppressPackageStartupMessages(library(rmapshaper))
suppressPackageStartupMessages(library(ggnewscale))
suppressPackageStartupMessages(library(caladaptr))
suppressPackageStartupMessages(library(nhdR))
suppressPackageStartupMessages(library(nhdplusTools))

# set global options
options(stringsAsFactors = FALSE)
options(tigris_use_cache = TRUE)
global_crs <- st_crs(4269)
global_crs_proj4 <- global_crs$proj4string
options(scipen = 999)
options(timeout = 3000)
rasterOptions(memfrac = .3)
parallel <- FALSE

# set up parallel computation
if(parallel) {
  num_cores <- detectCores()
  cl <- makeCluster(num_cores, output = "")
  registerDoParallel(cl)
}

# build custom functions and operators
# %notin%: operator that returns the negation of %in%
`%notin%` <- Negate(`%in%`)

# paste_na_rm(): function that pastes values together while dropping NAs
paste_na_rm <- function(x, collapse = ", ") {
  
  paste(x[!is.na(x)], collapse = collapse)
  
}

# build is.nan() method for data.frame objects
is.nan.data.frame <- function(x)
do.call(cbind, lapply(x, is.nan))

# build function that pulls CA boundary into global environment as sf object
get_ca_boundary <- function(crs) {
    states() %>%
      filter(NAME == "California") %>%
      rename(name = NAME) %>%
      dplyr::select(name) %>%
      st_transform(crs = crs)
}

# build function that quickly pulls up sf object attribute tables
view_flat <- function(sf_obj) {
  st_drop_geometry(sf_obj) %>%
    View(.)
}

# build a function that computes total stream length upstream of a segment
get_upstream_length <- function(comid, ut_network_df) {
  
  try(upstream_comids <- get_UT(ut_network_df, comid, distance = NULL))
  
  upstream_length_km <- ut_network_df %>%
    filter(COMID %in% upstream_comids) %>%
    summarize(total_length_km = sum(LENGTHKM)) %>%
    pull(total_length_km)
  
  return(upstream_length_km)
  
}
```

# Import restoration data

## DS734 - restoration focus watersheds
## DS168 - restoration project sites

```{r}
# create directories
if(!dir.exists(here("raw_data", "cdfw_ds734"))) {
  dir.create(here("raw_data", "cdfw_ds734"))
}

if(!dir.exists(here("raw_data", "cdfw_ds168"))) {
  dir.create(here("raw_data", "cdfw_ds168"))
}

# download spatial files from CDFW
######### ---> url and download here

# unzip zipped spatial files
unzip(zipfile = here("raw_data", "cdfw_ds734.zip"), overwrite = TRUE,
      exdir = here("raw_data", "cdfw_ds734"))

unzip(zipfile = here("raw_data", "cdfw_ds168.zip"), overwrite = TRUE,
      exdir = here("raw_data", "cdfw_ds168"))

# read in files as sf objects
# ds734: boundary regions for fisheries restoration grant program
# multipolygon
ds734 <- st_read(dsn = here("raw_data", "cdfw_ds734", "ds734.shp")) %>%
  st_transform(crs = global_crs)

# ds168: locations of fisheries restoration grant program projects
ds168 <- readOGR(dsn = here("raw_data", "cdfw_ds168", "ds168.gdb"),
                 layer = "ds168") %>%
  st_as_sf() %>%
  st_transform(crs = global_crs)

# ds168_ex: ???
# ds168: locations of fisheries restoration grant program projects
ds168_ex <- st_read(dsn = here("raw_data", "cdfw_ds168", "ds168.gdb"),
                    layer = "ds168_ex") %>%
  rename(project_id = ProjectID) %>%
  rename_with(tolower)
```

```{r}
# clean data
ds734 <- ds734 %>%
  rename(region = REGION,
         sub_region = SUBREGION,
         basin = BASIN,
         sub_basin = SUBBASIN,
         huc2 = HUC_2,
         huc4 = HUC_4,
         huc6 = HUC_6,
         huc8 = HUC_8,
         acres = ACRES,
         sq_miles = SQ_MILES,
         state_huc8 = HU_8_STATE,
         fips = FIPS_C,
         huc10_name = HU_10_NAME,
         huc10_sq_miles = HUC10_SqMi,
         llid = LLID,
         name = NAME,
         length_ft = LENGTH_FT,
         mouth = MOUTH,
         area_sq_miles = AREA_sq_mi)

ds168 <- ds168 %>%
  rename(project_id = ProjectID,
         worksite_id = WorksiteID,
         worksite_name = WorksiteNa,
         award_year = Award_Year) %>%
  dplyr::select(-WorksiteLa, - WorksiteLo) %>%
  left_join(ds168_ex, by = c("project_id", "award_year"))

# clean up
rm(ds168_ex)
```

# Classify projects

## Quick look

```{r}
# quickly visualize all the restoration sites
ca_boundary <- get_ca_boundary(crs = global_crs)

ggplot() +
  geom_sf(data = ca_boundary, fill = "lightgrey") +
  geom_sf(data = ms_simplify(ds734, keep = 0.05), fill = "lightblue") +
  geom_sf(data = ds168, aes(color = award_year)) +
  theme_minimal()
```

## Urban area association - incorporated and census-designated places

```{r}
# load census bureau "places" sf polygon objects
incorp_cdp <- places(state = "CA", year = 2020) %>%
  rename(place_fip = PLACEFP,
         geo_id = GEOID,
         name = NAME,
         name_w_type = NAMELSAD,
         type_code = LSAD,
         fips_code = CLASSFP,
         area_land = ALAND,
         area_water = AWATER) %>%
  dplyr::select(place_fip, geo_id, name, name_w_type, type_code,
                fips_code, area_land, area_water)

# visualize census places by type code
# which roughly aligns with incorporation status
ggplot() +
  geom_sf(data = ca_boundary, fill = "lightgrey") +
  geom_sf(data = ms_simplify(incorp_cdp, keep = 0.05),
          aes(fill = type_code),
          lwd = 0) +
  theme_minimal()
```

## Filter project for intersection with urban areas

```{r}
# filter restoration project sites to only those within census place boundaries
restoration_projects <- st_join(x = ds168, y = incorp_cdp, join = st_intersects, left = FALSE)

# quickly visualize restoration sites falling with census place boundaries
ggplot() +
  geom_sf(data = ca_boundary, fill = "lightgrey") +
  geom_sf(data = ms_simplify(ds734, keep = 0.05), fill = "lightblue") +
  geom_sf(data = restoration_projects, aes(color = award_year)) +
  theme_minimal()
```

## Clean up

```{r}
# clean up
rm(ds168, ds734, incorp_cdp)
```

# Import enriching data

## Watershed boundaries

### HUC8

```{r}
# create directory
if(!dir.exists(here("raw_data", "wbd"))) {
  dir.create(here("raw_data", "wbd"))
}

# download WBD
if(!file.exists(here("raw_data", "wbd", "WBD_National_GDB.zip"))) {
  download_wbd(outdir = here("raw_data", "wbd"), progress = TRUE) 
}

# read in HUC8 watersheds
if(TRUE) {
  huc8 <- readOGR(dsn = here("raw_data", "wbd", "WBD_National_GDB.gdb"),
                  layer = "WBDHU8") %>%
    st_as_sf(crs = global_crs) %>%
    mutate(california = grepl("CA", states, fixed = TRUE)) %>%
    filter(california) %>%
    ms_simplify(keep = 0.05) %>%
    st_intersection(y = ca_boundary) %>%
    rename(huc8_area_sqkm = areasqkm,
           huc8_name = name) %>%
    dplyr::select(huc8, huc8_name, huc8_area_sqkm)
}

# enrich restoration projects with HUC8
restoration_projects <- st_join(restoration_projects, huc8)
```

### HUC12 and ACE

```{r}
# create directory
if(!dir.exists(here("raw_data", "ace"))) {
  dir.create(here("raw_data", "ace"))
}

# specify url
ace_url <- "https://filelib.wildlife.ca.gov/Public/BDB/ACE/ACE_Summary_Datasets.zip"

# download file
if(!file.exists(here("raw_data", "ace", "ace_summary_datasets.zip"))) {
  download.file(url = ace_url,
                destfile = here("raw_data", "ace", "ACE_Summary_Datasets.zip"))
}

# unzip file
unzip(here("raw_data", "ace", "ACE_Summary_Datasets.zip"),
      exdir = here("raw_data", "ace"))

# read in and clean ACE dataset
huc12 <- readOGR(dsn = here("raw_data", "ace", "ACE_Summary_Datasets", "ds2743.gdb")) %>%
  st_as_sf() %>%
  st_transform(crs = global_crs) %>%
  ms_simplify(keep = 0.05) %>%
  st_intersection(y = ca_boundary) %>%
  rename(huc12 = HUC12,
         huc12_name = Name,
         native_aquatic_rank = NtvAqRankSW,
         native_aquatic_index = NtvAqSumSW,
         native_fish_count = NtvFish,
         native_aquatic_invert_count = NtvAqInvt,
         native_aquatic_amphib_count = NtvAqAmph,
         native_aquatic_reptile_count = NtvAqRept) %>%
  mutate(huc12_area_sqkm = drop_units(set_units(st_area(geometry), "km^2"))) %>%
  dplyr::select(huc12, huc12_name, huc12_area_sqkm,
                native_aquatic_rank, native_aquatic_index, native_fish_count,
                native_aquatic_invert_count, native_aquatic_amphib_count,
                native_aquatic_reptile_count)

# enrich restoration projects with HUC12 and ACE
restoration_projects <- st_join(restoration_projects, huc12) 

# clean up
rm(ace_url)
```

```{r}
# take a quick look at ACE data
ggplot() +
  geom_sf(data = huc12, aes(fill = native_aquatic_index), lwd = 0) +
  theme_minimal()
```

## NHD Flowlines

```{r}
# create directory
if(!dir.exists(here("raw_data", "nhd_flowlines"))) {
  dir.create(here("raw_data", "nhd_flowlines"))
}

# set nhdR download and directory paths
Sys.setenv(nhdR_path = here("raw_data", "nhd_flowlines"))

# download flowlines and attribute data for VPUs 17 (PNW) and 18 (CA)
suppressMessages(nhd_plus_get(vpu = 17, component = "NHDSnapshot"))
suppressMessages(nhd_plus_get(vpu = 18, component = "NHDSnapshot"))
suppressMessages(nhd_plus_get(vpu = 17, "NHDPlusAttributes"))
suppressMessages(nhd_plus_get(vpu = 18, "NHDPlusAttributes"))

# read in flowlines
flowlines_17 <- nhd_plus_load(vpu = 17,
                              component = "NHDSnapshot",
                              dsn = "NHDFlowline")

flowlines_18 <- nhd_plus_load(vpu = 18,
                              component = "NHDSnapshot",
                              dsn = "NHDFlowline")

flowlines <- rbind(flowlines_17, flowlines_18) %>%
  rename(length_km = LENGTHKM) %>%
  rename_with(.fn = tolower) %>%
  dplyr::select(comid, gnis_id, gnis_name, length_km, ftype) %>%
  st_join(y = ca_boundary, join = st_intersects, left = FALSE) %>%
  dplyr::select(-name) %>%
  filter(!ftype == "Coastline")

# download value-added attributes (original source: Hydroshare)
drive_download(file = as_id("1tpMnQDXD50jYQ5EtZJthOAKPc5squEn0"),
               path = here("raw_data", "nhd_flowlines", "vaa.zip"),
               overwrite = TRUE)

# unzip value-added attributes
unzip(zipfile = here("raw_data", "nhd_flowlines", "vaa.zip"),
      exdir = here("raw_data", "nhd_flowlines"))

# read in value-added attributes and filter for CA
vaa <- read_fst(path = here("raw_data", "nhd_flowlines", "nhdplusVAA.fst", "nhdplusVAA.fst")) %>%
  filter(comid %in% flowlines$comid)

# create vaa dataframe with specific column headings for upstream calcs
ut_network <- vaa %>%
  rename(COMID = comid,
         Pathlength = pathlength,
         LENGTHKM = lengthkm,
         Hydroseq = hydroseq,
         LevelPathI = levelpathi,
         DnHydroseq = dnhydroseq) %>%
  dplyr::select(COMID, Pathlength, LENGTHKM, Hydroseq, LevelPathI, DnHydroseq)

# clean vaa
vaa <- vaa %>%
  rename(stream_order = streamorde,
         length_km = lengthkm,
         tot_da_sqkm = totdasqkm) %>%
  dplyr::select(comid, stream_order,
                fcode, tot_da_sqkm, slope, roughness)

# add drainage area from value-added attributes to flowlines
flowlines <- left_join(x = flowlines, y = vaa, by = "comid")

# snap restoration projects to flowlines
restoration_projects <- st_join(restoration_projects, flowlines, st_nearest_feature)

# clean up
rm(flowlines_17, flowlines_18, vaa)
```

### Upstream drainage area and length attributes

```{r}
# compute upstream stream length (including tributaries) for each restoration project
restoration_projects <- restoration_projects %>%
  rowwise() %>%
  mutate(upstream_length_km = get_upstream_length(comid = comid,
                                                  ut_network_df = ut_network),
         drainage_density = upstream_length_km / tot_da_sqkm) %>%
  ungroup() %>%
  rowid_to_column(var = "index")

# clean up
rm(ut_network)
```

## Environmental flows

```{r}
# create directory
if(!dir.exists(here("raw_data", "eflows"))) {
  dir.create(here("raw_data", "eflows"))
}

# specify eflows url
eflows_url <- "https://s3-us-west-1.amazonaws.com/funcflow/resources/eflow_geodatabase.zip"

if(!file.exists(here("raw_data", "eflows", "eflows.zip"))) {
  download.file(url = eflows_url,
                destfile = here("raw_data", "eflows", "eflows.zip"))
}

# unzip eflows data
unzip(zipfile = here("raw_data", "eflows", "eflows.zip"),
      exdir = here("raw_data", "eflows"))

# read in eflows data
eflows <- st_read(here("raw_data", "eflows", "Final_Classification_9CLASS",
                       "Final_Classification_9CLASS.shp")) %>%
  st_transform(crs = global_crs) %>%
  rename(eflows_class = CLASS,
         comid = COMID) %>%
  dplyr::select(eflows_class, comid)

# add eflows to restoration projects
restoration_projects <- left_join(restoration_projects, st_drop_geometry(eflows),
                                  by = "comid")

# clean up
rm(eflows, eflows_url)
```

## Precipitation - ERRORS, asked Andy to resolve in package

```{r}
if(FALSE) {
  # get grid of precip data coverage
  loca <- ca_locagrid_geom() %>%
    st_transform(crs = global_crs)
  
  # trim restoration projects dataset and
  # specify coordinates of restoration projects for API call
  restoration_coords <- st_join(restoration_projects, loca, left = FALSE) %>%
    st_drop_geometry() %>%
    dplyr::select(center_longitude, center_latitude, index) %>%
    rename(x = center_longitude,
           y = center_latitude)
  
  # generate a precip API call
  precip_api_call <- ca_loc_pt(x = ca_apireq(),
                               dplyr::select(restoration_coords, x, y),
                               id = restoration_coords$index) %>%
    ca_gcm("ens32avg") %>%
    ca_scenario("historical") %>%
    ca_cvar("pr") %>%
    ca_period("year") %>%
    ca_years(start = 1980, end = 2005)
  
  # make API call for precip data
  precip <- precip_api_call %>%
    ca_getvals_tbl(quiet = TRUE)
}
```

## California Stream Condition Index

```{r}
if(!dir.exists(here("raw_data", "csci"))) {
  dir.create(here("raw_data", "csci"))
}

csci_url <- "https://indicators.ucdavis.edu/cwip/sites/default/files/data/indicator_59452/data_59452_all.csv"

# download file
if(!file.exists(here("raw_data", "csci", "csci_all.csv"))) {
  download.file(url = csci_url,
                destfile = here("raw_data", "csci", "csci_all.csv"))
}

csci <- read_csv(here("raw_data", "csci", "csci_all.csv"),
                     col_names = TRUE) %>%
  rename(index = "...1") %>%
  group_by(station_code) %>%
  summarize(worst_csci_score = min(csci_score, na.rm = TRUE),
            cwip_score = cwip_score[which.min(csci_score)],
            stream_name = stream_name[which.min(csci_score)],
            station_code = station_code[which.min(csci_score)],
            sample_date = sample_date[which.min(csci_score)],
            latitude = latitude[which.min(csci_score)],
            longitude = longitude[which.min(csci_score)]) %>%
  st_as_sf(coords = c("longitude", "latitude"), crs = global_crs)

# clean up
rm(csci_url)
```

```{r}
ggplot() +
  geom_sf(data = ca_boundary) +
  geom_sf(data = csci, aes(color = worst_csci_score))
```

## Nitrates

```{r}
if(!dir.exists(here("raw_data", "nitrates"))) {
  dir.create(here("raw_data", "nitrates"))
}

nitrates_url <- "https://indicators.ucdavis.edu/cwip/sites/default/files/data/indicator_32232/data_32232_all.csv"

# download file
if(!file.exists(here("raw_data", "nitrates", "nitrates_all.csv"))) {
  download.file(url = nitrates_url,
                destfile = here("raw_data", "nitrates", "nitrates_all.csv"))
}

nitrates <- read_csv(here("raw_data", "nitrates", "nitrates_all.csv"),
                     col_names = TRUE) %>%
  rename(index = "...1") %>%
  group_by(code) %>%
  summarize(worst_nitrate_score = min(score, na.rm = TRUE),
            name = name[which.min(score)],
            code = code[which.min(score)],
            date = date[which.min(score)],
            lat = lat[which.min(score)],
            lon = lon[which.min(score)]) %>%
  st_as_sf(coords = c("lon", "lat"), crs = global_crs)

# clean up
rm(nitrates_url)
```

```{r}
ggplot() +
  geom_sf(data = ca_boundary) +
  geom_sf(data = nitrates, aes(color = worst_nitrate_score))
```

## 303d Listed Waterbodies

```{r}
# create directory
if(!dir.exists(here("raw_data", "303d"))) {
  dir.create(here("raw_data", "303d"))
}

# specify url
waterbodies_303d_lines_url <- "https://gispublic.waterboards.ca.gov/webmap/303d_2014_2016/files/IR_1416_Impaired_Lines.zip"

# download file
if(!file.exists(here("raw_data", "303d", "IR_1416_Impaired_Lines.zip"))) {
  download.file(url = waterbodies_303d_lines_url,
                destfile = here("raw_data", "303d", "IR_1416_Impaired_Lines.zip"))
}

# unzip file
unzip(here("raw_data", "303d", "IR_1416_Impaired_Lines.zip"),
      exdir = here("raw_data", "303d"))

# specify url
waterbodies_303d_polygons_url <- "https://gispublic.waterboards.ca.gov/webmap/303d_2014_2016/files/IR_1416_Impaired_Polys.zip"

# download file
if(!file.exists(here("raw_data", "303d", "IR_1416_Impaired_Polys.zip"))) {
  download.file(url = waterbodies_303d_polygons_url,
                destfile = here("raw_data", "303d", "IR_1416_Impaired_Polys.zip"))
}

# unzip file
unzip(here("raw_data", "303d", "IR_1416_Impaired_Polys.zip"),
      exdir = here("raw_data", "303d"))

# read in
waterbodies_303d_lines <- st_read(here("raw_data", "303d", "IR_1416_Impaired_Lines")) %>%
  st_transform(crs = global_crs)

waterbodies_303d_polygons <- st_read(here("raw_data", "303d", "IR_1416_Impaired_Polys")) %>%
  st_transform(crs = global_crs)

# clean up
rm(waterbodies_303d_lines_url, waterbodies_303d_polygons_url)
```
